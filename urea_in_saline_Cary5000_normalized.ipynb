{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3b67e23",
   "metadata": {},
   "source": [
    "# Urea in saline, Cary5000, normalized\n",
    "Data from Feb. 1, 11, and 22, 2022  \n",
    "Measured with the Cary5000 in UW Chemistry Student Facility  \n",
    "Blank to air  \n",
    "Background is water  \n",
    "Data has been normalized to the largest absorbance per spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7544efcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "\n",
    "# Pandas library for the pandas dataframes\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd   \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Set larger fontsize for all plots\n",
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac580ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "data = pd.read_csv('Datasets/urea_in_saline_cary5000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a0a52d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Urea Concentration (mM)</th>\n",
       "      <th>Date Measured</th>\n",
       "      <th>Type</th>\n",
       "      <th>Process</th>\n",
       "      <th>Solvent</th>\n",
       "      <th>2500</th>\n",
       "      <th>2499</th>\n",
       "      <th>2498</th>\n",
       "      <th>2497</th>\n",
       "      <th>2496</th>\n",
       "      <th>...</th>\n",
       "      <th>199</th>\n",
       "      <th>198</th>\n",
       "      <th>197</th>\n",
       "      <th>196</th>\n",
       "      <th>195</th>\n",
       "      <th>194</th>\n",
       "      <th>193</th>\n",
       "      <th>192</th>\n",
       "      <th>191</th>\n",
       "      <th>190</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb. 1, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.298431</td>\n",
       "      <td>0.301341</td>\n",
       "      <td>0.304291</td>\n",
       "      <td>0.306282</td>\n",
       "      <td>0.308359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361543</td>\n",
       "      <td>0.366255</td>\n",
       "      <td>0.368864</td>\n",
       "      <td>0.378832</td>\n",
       "      <td>0.378431</td>\n",
       "      <td>0.393099</td>\n",
       "      <td>0.397457</td>\n",
       "      <td>0.383589</td>\n",
       "      <td>0.416702</td>\n",
       "      <td>0.412296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb. 1, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.307994</td>\n",
       "      <td>0.310840</td>\n",
       "      <td>0.313797</td>\n",
       "      <td>0.315632</td>\n",
       "      <td>0.317241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355790</td>\n",
       "      <td>0.360166</td>\n",
       "      <td>0.362703</td>\n",
       "      <td>0.372803</td>\n",
       "      <td>0.372285</td>\n",
       "      <td>0.386894</td>\n",
       "      <td>0.390989</td>\n",
       "      <td>0.377885</td>\n",
       "      <td>0.410304</td>\n",
       "      <td>0.406783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>Feb. 1, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.291755</td>\n",
       "      <td>0.300952</td>\n",
       "      <td>0.303801</td>\n",
       "      <td>0.306101</td>\n",
       "      <td>0.307908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354902</td>\n",
       "      <td>0.359146</td>\n",
       "      <td>0.361506</td>\n",
       "      <td>0.370988</td>\n",
       "      <td>0.370830</td>\n",
       "      <td>0.384763</td>\n",
       "      <td>0.388561</td>\n",
       "      <td>0.375848</td>\n",
       "      <td>0.407207</td>\n",
       "      <td>0.401769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>Feb. 1, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.306774</td>\n",
       "      <td>0.309784</td>\n",
       "      <td>0.312549</td>\n",
       "      <td>0.314443</td>\n",
       "      <td>0.316351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350314</td>\n",
       "      <td>0.354415</td>\n",
       "      <td>0.356987</td>\n",
       "      <td>0.365899</td>\n",
       "      <td>0.365903</td>\n",
       "      <td>0.379756</td>\n",
       "      <td>0.383695</td>\n",
       "      <td>0.371102</td>\n",
       "      <td>0.402973</td>\n",
       "      <td>0.397271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Feb. 1, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.298964</td>\n",
       "      <td>0.302140</td>\n",
       "      <td>0.304847</td>\n",
       "      <td>0.307096</td>\n",
       "      <td>0.308640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.364504</td>\n",
       "      <td>0.367812</td>\n",
       "      <td>0.370143</td>\n",
       "      <td>0.380391</td>\n",
       "      <td>0.380485</td>\n",
       "      <td>0.394986</td>\n",
       "      <td>0.399000</td>\n",
       "      <td>0.385428</td>\n",
       "      <td>0.418334</td>\n",
       "      <td>0.414698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Feb. 1, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.307497</td>\n",
       "      <td>0.310426</td>\n",
       "      <td>0.313009</td>\n",
       "      <td>0.315191</td>\n",
       "      <td>0.316597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355023</td>\n",
       "      <td>0.358568</td>\n",
       "      <td>0.360716</td>\n",
       "      <td>0.370611</td>\n",
       "      <td>0.370509</td>\n",
       "      <td>0.384603</td>\n",
       "      <td>0.388456</td>\n",
       "      <td>0.375809</td>\n",
       "      <td>0.408066</td>\n",
       "      <td>0.403740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Feb. 1, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.298065</td>\n",
       "      <td>0.301234</td>\n",
       "      <td>0.304046</td>\n",
       "      <td>0.306255</td>\n",
       "      <td>0.307782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357557</td>\n",
       "      <td>0.360010</td>\n",
       "      <td>0.362341</td>\n",
       "      <td>0.372112</td>\n",
       "      <td>0.371795</td>\n",
       "      <td>0.386025</td>\n",
       "      <td>0.389515</td>\n",
       "      <td>0.376903</td>\n",
       "      <td>0.408608</td>\n",
       "      <td>0.403582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Feb. 1, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.307334</td>\n",
       "      <td>0.310431</td>\n",
       "      <td>0.312971</td>\n",
       "      <td>0.315266</td>\n",
       "      <td>0.316912</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351732</td>\n",
       "      <td>0.354325</td>\n",
       "      <td>0.356437</td>\n",
       "      <td>0.365661</td>\n",
       "      <td>0.365655</td>\n",
       "      <td>0.379323</td>\n",
       "      <td>0.382975</td>\n",
       "      <td>0.370680</td>\n",
       "      <td>0.401890</td>\n",
       "      <td>0.396821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Feb. 1, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.308158</td>\n",
       "      <td>0.311207</td>\n",
       "      <td>0.313723</td>\n",
       "      <td>0.315884</td>\n",
       "      <td>0.317152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358487</td>\n",
       "      <td>0.360573</td>\n",
       "      <td>0.362755</td>\n",
       "      <td>0.372427</td>\n",
       "      <td>0.372193</td>\n",
       "      <td>0.386862</td>\n",
       "      <td>0.390842</td>\n",
       "      <td>0.377482</td>\n",
       "      <td>0.409925</td>\n",
       "      <td>0.406347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Feb. 1, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.299565</td>\n",
       "      <td>0.302802</td>\n",
       "      <td>0.305466</td>\n",
       "      <td>0.307841</td>\n",
       "      <td>0.309226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366400</td>\n",
       "      <td>0.368517</td>\n",
       "      <td>0.370969</td>\n",
       "      <td>0.381093</td>\n",
       "      <td>0.380869</td>\n",
       "      <td>0.395695</td>\n",
       "      <td>0.399594</td>\n",
       "      <td>0.385799</td>\n",
       "      <td>0.418890</td>\n",
       "      <td>0.415050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.0</td>\n",
       "      <td>Feb. 1, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.307448</td>\n",
       "      <td>0.310834</td>\n",
       "      <td>0.312944</td>\n",
       "      <td>0.315218</td>\n",
       "      <td>0.316664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355875</td>\n",
       "      <td>0.357180</td>\n",
       "      <td>0.359041</td>\n",
       "      <td>0.368811</td>\n",
       "      <td>0.368408</td>\n",
       "      <td>0.382670</td>\n",
       "      <td>0.386367</td>\n",
       "      <td>0.373508</td>\n",
       "      <td>0.405086</td>\n",
       "      <td>0.401146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15.0</td>\n",
       "      <td>Feb. 1, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.306702</td>\n",
       "      <td>0.310193</td>\n",
       "      <td>0.312421</td>\n",
       "      <td>0.314593</td>\n",
       "      <td>0.316176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352700</td>\n",
       "      <td>0.354044</td>\n",
       "      <td>0.355942</td>\n",
       "      <td>0.365007</td>\n",
       "      <td>0.365193</td>\n",
       "      <td>0.379188</td>\n",
       "      <td>0.382527</td>\n",
       "      <td>0.370025</td>\n",
       "      <td>0.401027</td>\n",
       "      <td>0.395582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Feb. 1, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.297953</td>\n",
       "      <td>0.301360</td>\n",
       "      <td>0.303603</td>\n",
       "      <td>0.306059</td>\n",
       "      <td>0.307628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360060</td>\n",
       "      <td>0.360952</td>\n",
       "      <td>0.363184</td>\n",
       "      <td>0.372921</td>\n",
       "      <td>0.372698</td>\n",
       "      <td>0.387175</td>\n",
       "      <td>0.391027</td>\n",
       "      <td>0.377442</td>\n",
       "      <td>0.409135</td>\n",
       "      <td>0.404400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Feb. 1, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.307150</td>\n",
       "      <td>0.310361</td>\n",
       "      <td>0.312605</td>\n",
       "      <td>0.314883</td>\n",
       "      <td>0.316188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.357042</td>\n",
       "      <td>0.358189</td>\n",
       "      <td>0.360090</td>\n",
       "      <td>0.370128</td>\n",
       "      <td>0.369602</td>\n",
       "      <td>0.383912</td>\n",
       "      <td>0.387541</td>\n",
       "      <td>0.374382</td>\n",
       "      <td>0.406033</td>\n",
       "      <td>0.401455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb. 11, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.550556</td>\n",
       "      <td>0.552751</td>\n",
       "      <td>0.555931</td>\n",
       "      <td>0.558297</td>\n",
       "      <td>0.559510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578482</td>\n",
       "      <td>0.585733</td>\n",
       "      <td>0.590542</td>\n",
       "      <td>0.613888</td>\n",
       "      <td>0.613578</td>\n",
       "      <td>0.641193</td>\n",
       "      <td>0.658152</td>\n",
       "      <td>0.639821</td>\n",
       "      <td>0.697857</td>\n",
       "      <td>0.737987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb. 11, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.511389</td>\n",
       "      <td>0.523129</td>\n",
       "      <td>0.528769</td>\n",
       "      <td>0.532065</td>\n",
       "      <td>0.533796</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634057</td>\n",
       "      <td>0.641900</td>\n",
       "      <td>0.648078</td>\n",
       "      <td>0.674654</td>\n",
       "      <td>0.673527</td>\n",
       "      <td>0.704385</td>\n",
       "      <td>0.725900</td>\n",
       "      <td>0.705568</td>\n",
       "      <td>0.765985</td>\n",
       "      <td>0.817863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb. 11, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.522742</td>\n",
       "      <td>0.533131</td>\n",
       "      <td>0.538122</td>\n",
       "      <td>0.540534</td>\n",
       "      <td>0.541680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575887</td>\n",
       "      <td>0.582950</td>\n",
       "      <td>0.588388</td>\n",
       "      <td>0.611248</td>\n",
       "      <td>0.610550</td>\n",
       "      <td>0.638514</td>\n",
       "      <td>0.656656</td>\n",
       "      <td>0.636711</td>\n",
       "      <td>0.694189</td>\n",
       "      <td>0.735069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100.0</td>\n",
       "      <td>Feb. 11, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.515298</td>\n",
       "      <td>0.526676</td>\n",
       "      <td>0.532259</td>\n",
       "      <td>0.535775</td>\n",
       "      <td>0.537460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.641014</td>\n",
       "      <td>0.647002</td>\n",
       "      <td>0.652938</td>\n",
       "      <td>0.679457</td>\n",
       "      <td>0.678738</td>\n",
       "      <td>0.709768</td>\n",
       "      <td>0.730871</td>\n",
       "      <td>0.710464</td>\n",
       "      <td>0.771010</td>\n",
       "      <td>0.823517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100.0</td>\n",
       "      <td>Feb. 11, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.558547</td>\n",
       "      <td>0.568608</td>\n",
       "      <td>0.573251</td>\n",
       "      <td>0.575730</td>\n",
       "      <td>0.576395</td>\n",
       "      <td>...</td>\n",
       "      <td>0.597621</td>\n",
       "      <td>0.602674</td>\n",
       "      <td>0.608327</td>\n",
       "      <td>0.632288</td>\n",
       "      <td>0.631513</td>\n",
       "      <td>0.660739</td>\n",
       "      <td>0.679488</td>\n",
       "      <td>0.659816</td>\n",
       "      <td>0.718383</td>\n",
       "      <td>0.763266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100.0</td>\n",
       "      <td>Feb. 11, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.516793</td>\n",
       "      <td>0.527195</td>\n",
       "      <td>0.532015</td>\n",
       "      <td>0.534570</td>\n",
       "      <td>0.535710</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567889</td>\n",
       "      <td>0.572114</td>\n",
       "      <td>0.577310</td>\n",
       "      <td>0.599792</td>\n",
       "      <td>0.599206</td>\n",
       "      <td>0.626687</td>\n",
       "      <td>0.644546</td>\n",
       "      <td>0.625807</td>\n",
       "      <td>0.681970</td>\n",
       "      <td>0.719499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>200.0</td>\n",
       "      <td>Feb. 11, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.538166</td>\n",
       "      <td>0.548436</td>\n",
       "      <td>0.552928</td>\n",
       "      <td>0.555132</td>\n",
       "      <td>0.556085</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569908</td>\n",
       "      <td>0.574890</td>\n",
       "      <td>0.579650</td>\n",
       "      <td>0.602128</td>\n",
       "      <td>0.601803</td>\n",
       "      <td>0.629407</td>\n",
       "      <td>0.646811</td>\n",
       "      <td>0.628488</td>\n",
       "      <td>0.685319</td>\n",
       "      <td>0.723862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>200.0</td>\n",
       "      <td>Feb. 11, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.506721</td>\n",
       "      <td>0.518304</td>\n",
       "      <td>0.523846</td>\n",
       "      <td>0.527196</td>\n",
       "      <td>0.528963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.624452</td>\n",
       "      <td>0.630818</td>\n",
       "      <td>0.636017</td>\n",
       "      <td>0.661799</td>\n",
       "      <td>0.660737</td>\n",
       "      <td>0.691413</td>\n",
       "      <td>0.711125</td>\n",
       "      <td>0.691607</td>\n",
       "      <td>0.752104</td>\n",
       "      <td>0.800356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>200.0</td>\n",
       "      <td>Feb. 11, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.510741</td>\n",
       "      <td>0.521088</td>\n",
       "      <td>0.525895</td>\n",
       "      <td>0.528518</td>\n",
       "      <td>0.529579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558759</td>\n",
       "      <td>0.563326</td>\n",
       "      <td>0.568172</td>\n",
       "      <td>0.590187</td>\n",
       "      <td>0.589908</td>\n",
       "      <td>0.616733</td>\n",
       "      <td>0.633844</td>\n",
       "      <td>0.615769</td>\n",
       "      <td>0.671310</td>\n",
       "      <td>0.707839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>400.0</td>\n",
       "      <td>Feb. 11, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.547091</td>\n",
       "      <td>0.557262</td>\n",
       "      <td>0.561686</td>\n",
       "      <td>0.563918</td>\n",
       "      <td>0.564966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584689</td>\n",
       "      <td>0.589650</td>\n",
       "      <td>0.594564</td>\n",
       "      <td>0.617957</td>\n",
       "      <td>0.617361</td>\n",
       "      <td>0.645926</td>\n",
       "      <td>0.664113</td>\n",
       "      <td>0.645253</td>\n",
       "      <td>0.702766</td>\n",
       "      <td>0.743643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>400.0</td>\n",
       "      <td>Feb. 11, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.511753</td>\n",
       "      <td>0.522352</td>\n",
       "      <td>0.527095</td>\n",
       "      <td>0.529542</td>\n",
       "      <td>0.530865</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560366</td>\n",
       "      <td>0.565146</td>\n",
       "      <td>0.570067</td>\n",
       "      <td>0.592316</td>\n",
       "      <td>0.591667</td>\n",
       "      <td>0.618951</td>\n",
       "      <td>0.635933</td>\n",
       "      <td>0.617671</td>\n",
       "      <td>0.673090</td>\n",
       "      <td>0.709623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>400.0</td>\n",
       "      <td>Feb. 11, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.519048</td>\n",
       "      <td>0.530828</td>\n",
       "      <td>0.536697</td>\n",
       "      <td>0.540083</td>\n",
       "      <td>0.541840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.649341</td>\n",
       "      <td>0.655734</td>\n",
       "      <td>0.661060</td>\n",
       "      <td>0.688663</td>\n",
       "      <td>0.687729</td>\n",
       "      <td>0.718974</td>\n",
       "      <td>0.741030</td>\n",
       "      <td>0.721225</td>\n",
       "      <td>0.780686</td>\n",
       "      <td>0.835192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>600.0</td>\n",
       "      <td>Feb. 11, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.518204</td>\n",
       "      <td>0.528919</td>\n",
       "      <td>0.533447</td>\n",
       "      <td>0.536251</td>\n",
       "      <td>0.537478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569300</td>\n",
       "      <td>0.574208</td>\n",
       "      <td>0.579266</td>\n",
       "      <td>0.602097</td>\n",
       "      <td>0.601460</td>\n",
       "      <td>0.629124</td>\n",
       "      <td>0.646164</td>\n",
       "      <td>0.627012</td>\n",
       "      <td>0.683642</td>\n",
       "      <td>0.722129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>600.0</td>\n",
       "      <td>Feb. 11, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.532106</td>\n",
       "      <td>0.542228</td>\n",
       "      <td>0.546772</td>\n",
       "      <td>0.549238</td>\n",
       "      <td>0.550202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564819</td>\n",
       "      <td>0.569334</td>\n",
       "      <td>0.574500</td>\n",
       "      <td>0.596655</td>\n",
       "      <td>0.596382</td>\n",
       "      <td>0.623635</td>\n",
       "      <td>0.640834</td>\n",
       "      <td>0.621749</td>\n",
       "      <td>0.678265</td>\n",
       "      <td>0.715029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>600.0</td>\n",
       "      <td>Feb. 11, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.535094</td>\n",
       "      <td>0.546909</td>\n",
       "      <td>0.552853</td>\n",
       "      <td>0.556697</td>\n",
       "      <td>0.558499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681535</td>\n",
       "      <td>0.688727</td>\n",
       "      <td>0.694635</td>\n",
       "      <td>0.723585</td>\n",
       "      <td>0.722468</td>\n",
       "      <td>0.755459</td>\n",
       "      <td>0.779367</td>\n",
       "      <td>0.757648</td>\n",
       "      <td>0.818729</td>\n",
       "      <td>0.880280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb. 22, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.521143</td>\n",
       "      <td>0.528103</td>\n",
       "      <td>0.532526</td>\n",
       "      <td>0.535269</td>\n",
       "      <td>0.537373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.654794</td>\n",
       "      <td>0.663927</td>\n",
       "      <td>0.668777</td>\n",
       "      <td>0.694226</td>\n",
       "      <td>0.690244</td>\n",
       "      <td>0.718680</td>\n",
       "      <td>0.730858</td>\n",
       "      <td>0.708556</td>\n",
       "      <td>0.749574</td>\n",
       "      <td>0.789926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb. 22, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.533065</td>\n",
       "      <td>0.539048</td>\n",
       "      <td>0.543052</td>\n",
       "      <td>0.545274</td>\n",
       "      <td>0.546327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594621</td>\n",
       "      <td>0.602465</td>\n",
       "      <td>0.607290</td>\n",
       "      <td>0.629643</td>\n",
       "      <td>0.627050</td>\n",
       "      <td>0.652382</td>\n",
       "      <td>0.662272</td>\n",
       "      <td>0.642538</td>\n",
       "      <td>0.682274</td>\n",
       "      <td>0.713994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Feb. 22, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.568167</td>\n",
       "      <td>0.573779</td>\n",
       "      <td>0.577161</td>\n",
       "      <td>0.579204</td>\n",
       "      <td>0.580219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600184</td>\n",
       "      <td>0.608688</td>\n",
       "      <td>0.613170</td>\n",
       "      <td>0.636689</td>\n",
       "      <td>0.633971</td>\n",
       "      <td>0.661168</td>\n",
       "      <td>0.673055</td>\n",
       "      <td>0.652647</td>\n",
       "      <td>0.693504</td>\n",
       "      <td>0.729793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Feb. 22, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.547406</td>\n",
       "      <td>0.554294</td>\n",
       "      <td>0.559353</td>\n",
       "      <td>0.562185</td>\n",
       "      <td>0.564044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715527</td>\n",
       "      <td>0.725575</td>\n",
       "      <td>0.730782</td>\n",
       "      <td>0.759440</td>\n",
       "      <td>0.754604</td>\n",
       "      <td>0.784805</td>\n",
       "      <td>0.799221</td>\n",
       "      <td>0.775027</td>\n",
       "      <td>0.816957</td>\n",
       "      <td>0.865353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Feb. 22, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.537541</td>\n",
       "      <td>0.543268</td>\n",
       "      <td>0.546478</td>\n",
       "      <td>0.548426</td>\n",
       "      <td>0.549551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571308</td>\n",
       "      <td>0.578658</td>\n",
       "      <td>0.583329</td>\n",
       "      <td>0.604616</td>\n",
       "      <td>0.601764</td>\n",
       "      <td>0.626755</td>\n",
       "      <td>0.636840</td>\n",
       "      <td>0.616613</td>\n",
       "      <td>0.655967</td>\n",
       "      <td>0.684586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Feb. 22, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.549876</td>\n",
       "      <td>0.557226</td>\n",
       "      <td>0.561918</td>\n",
       "      <td>0.565071</td>\n",
       "      <td>0.567110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712978</td>\n",
       "      <td>0.722635</td>\n",
       "      <td>0.726949</td>\n",
       "      <td>0.755167</td>\n",
       "      <td>0.750790</td>\n",
       "      <td>0.781049</td>\n",
       "      <td>0.795428</td>\n",
       "      <td>0.771656</td>\n",
       "      <td>0.813327</td>\n",
       "      <td>0.862812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Feb. 22, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.566020</td>\n",
       "      <td>0.571711</td>\n",
       "      <td>0.575421</td>\n",
       "      <td>0.577282</td>\n",
       "      <td>0.578127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.597686</td>\n",
       "      <td>0.605021</td>\n",
       "      <td>0.609750</td>\n",
       "      <td>0.633627</td>\n",
       "      <td>0.630575</td>\n",
       "      <td>0.657439</td>\n",
       "      <td>0.669161</td>\n",
       "      <td>0.649045</td>\n",
       "      <td>0.689069</td>\n",
       "      <td>0.725162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>100.0</td>\n",
       "      <td>Feb. 22, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.525918</td>\n",
       "      <td>0.532922</td>\n",
       "      <td>0.537205</td>\n",
       "      <td>0.539894</td>\n",
       "      <td>0.542135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662726</td>\n",
       "      <td>0.668185</td>\n",
       "      <td>0.672794</td>\n",
       "      <td>0.698132</td>\n",
       "      <td>0.693970</td>\n",
       "      <td>0.722730</td>\n",
       "      <td>0.734433</td>\n",
       "      <td>0.712463</td>\n",
       "      <td>0.752627</td>\n",
       "      <td>0.795034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>100.0</td>\n",
       "      <td>Feb. 22, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.533989</td>\n",
       "      <td>0.539853</td>\n",
       "      <td>0.543294</td>\n",
       "      <td>0.545048</td>\n",
       "      <td>0.546487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570347</td>\n",
       "      <td>0.574531</td>\n",
       "      <td>0.578717</td>\n",
       "      <td>0.599633</td>\n",
       "      <td>0.597276</td>\n",
       "      <td>0.621449</td>\n",
       "      <td>0.631180</td>\n",
       "      <td>0.612071</td>\n",
       "      <td>0.649248</td>\n",
       "      <td>0.678345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>600.0</td>\n",
       "      <td>Feb. 22, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.556639</td>\n",
       "      <td>0.562234</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.567761</td>\n",
       "      <td>0.568793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584056</td>\n",
       "      <td>0.588426</td>\n",
       "      <td>0.592124</td>\n",
       "      <td>0.614623</td>\n",
       "      <td>0.611320</td>\n",
       "      <td>0.637047</td>\n",
       "      <td>0.647798</td>\n",
       "      <td>0.627007</td>\n",
       "      <td>0.666715</td>\n",
       "      <td>0.700410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>600.0</td>\n",
       "      <td>Feb. 22, 2022</td>\n",
       "      <td>raw</td>\n",
       "      <td>normalized</td>\n",
       "      <td>saline</td>\n",
       "      <td>0.522704</td>\n",
       "      <td>0.529801</td>\n",
       "      <td>0.534197</td>\n",
       "      <td>0.537025</td>\n",
       "      <td>0.539145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655903</td>\n",
       "      <td>0.661424</td>\n",
       "      <td>0.666222</td>\n",
       "      <td>0.690589</td>\n",
       "      <td>0.686825</td>\n",
       "      <td>0.714056</td>\n",
       "      <td>0.726491</td>\n",
       "      <td>0.704049</td>\n",
       "      <td>0.743363</td>\n",
       "      <td>0.784428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows Ã— 2316 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Urea Concentration (mM)  Date Measured Type     Process Solvent      2500  \\\n",
       "0                       0.0   Feb. 1, 2022  raw  normalized  saline  0.298431   \n",
       "1                       0.0   Feb. 1, 2022  raw  normalized  saline  0.307994   \n",
       "2                       0.5   Feb. 1, 2022  raw  normalized  saline  0.291755   \n",
       "3                       0.5   Feb. 1, 2022  raw  normalized  saline  0.306774   \n",
       "4                       2.0   Feb. 1, 2022  raw  normalized  saline  0.298964   \n",
       "5                       2.0   Feb. 1, 2022  raw  normalized  saline  0.307497   \n",
       "6                       5.0   Feb. 1, 2022  raw  normalized  saline  0.298065   \n",
       "7                       5.0   Feb. 1, 2022  raw  normalized  saline  0.307334   \n",
       "8                       8.0   Feb. 1, 2022  raw  normalized  saline  0.308158   \n",
       "9                       8.0   Feb. 1, 2022  raw  normalized  saline  0.299565   \n",
       "10                     15.0   Feb. 1, 2022  raw  normalized  saline  0.307448   \n",
       "11                     15.0   Feb. 1, 2022  raw  normalized  saline  0.306702   \n",
       "12                     20.0   Feb. 1, 2022  raw  normalized  saline  0.297953   \n",
       "13                     20.0   Feb. 1, 2022  raw  normalized  saline  0.307150   \n",
       "14                      0.0  Feb. 11, 2022  raw  normalized  saline  0.550556   \n",
       "15                      0.0  Feb. 11, 2022  raw  normalized  saline  0.511389   \n",
       "16                      0.0  Feb. 11, 2022  raw  normalized  saline  0.522742   \n",
       "17                    100.0  Feb. 11, 2022  raw  normalized  saline  0.515298   \n",
       "18                    100.0  Feb. 11, 2022  raw  normalized  saline  0.558547   \n",
       "19                    100.0  Feb. 11, 2022  raw  normalized  saline  0.516793   \n",
       "20                    200.0  Feb. 11, 2022  raw  normalized  saline  0.538166   \n",
       "21                    200.0  Feb. 11, 2022  raw  normalized  saline  0.506721   \n",
       "22                    200.0  Feb. 11, 2022  raw  normalized  saline  0.510741   \n",
       "23                    400.0  Feb. 11, 2022  raw  normalized  saline  0.547091   \n",
       "24                    400.0  Feb. 11, 2022  raw  normalized  saline  0.511753   \n",
       "25                    400.0  Feb. 11, 2022  raw  normalized  saline  0.519048   \n",
       "26                    600.0  Feb. 11, 2022  raw  normalized  saline  0.518204   \n",
       "27                    600.0  Feb. 11, 2022  raw  normalized  saline  0.532106   \n",
       "28                    600.0  Feb. 11, 2022  raw  normalized  saline  0.535094   \n",
       "29                      0.0  Feb. 22, 2022  raw  normalized  saline  0.521143   \n",
       "30                      0.0  Feb. 22, 2022  raw  normalized  saline  0.533065   \n",
       "31                      0.0  Feb. 22, 2022  raw  normalized  saline  0.568167   \n",
       "32                      2.0  Feb. 22, 2022  raw  normalized  saline  0.547406   \n",
       "33                      2.0  Feb. 22, 2022  raw  normalized  saline  0.537541   \n",
       "34                     10.0  Feb. 22, 2022  raw  normalized  saline  0.549876   \n",
       "35                     10.0  Feb. 22, 2022  raw  normalized  saline  0.566020   \n",
       "36                    100.0  Feb. 22, 2022  raw  normalized  saline  0.525918   \n",
       "37                    100.0  Feb. 22, 2022  raw  normalized  saline  0.533989   \n",
       "38                    600.0  Feb. 22, 2022  raw  normalized  saline  0.556639   \n",
       "39                    600.0  Feb. 22, 2022  raw  normalized  saline  0.522704   \n",
       "\n",
       "        2499      2498      2497      2496  ...       199       198       197  \\\n",
       "0   0.301341  0.304291  0.306282  0.308359  ...  0.361543  0.366255  0.368864   \n",
       "1   0.310840  0.313797  0.315632  0.317241  ...  0.355790  0.360166  0.362703   \n",
       "2   0.300952  0.303801  0.306101  0.307908  ...  0.354902  0.359146  0.361506   \n",
       "3   0.309784  0.312549  0.314443  0.316351  ...  0.350314  0.354415  0.356987   \n",
       "4   0.302140  0.304847  0.307096  0.308640  ...  0.364504  0.367812  0.370143   \n",
       "5   0.310426  0.313009  0.315191  0.316597  ...  0.355023  0.358568  0.360716   \n",
       "6   0.301234  0.304046  0.306255  0.307782  ...  0.357557  0.360010  0.362341   \n",
       "7   0.310431  0.312971  0.315266  0.316912  ...  0.351732  0.354325  0.356437   \n",
       "8   0.311207  0.313723  0.315884  0.317152  ...  0.358487  0.360573  0.362755   \n",
       "9   0.302802  0.305466  0.307841  0.309226  ...  0.366400  0.368517  0.370969   \n",
       "10  0.310834  0.312944  0.315218  0.316664  ...  0.355875  0.357180  0.359041   \n",
       "11  0.310193  0.312421  0.314593  0.316176  ...  0.352700  0.354044  0.355942   \n",
       "12  0.301360  0.303603  0.306059  0.307628  ...  0.360060  0.360952  0.363184   \n",
       "13  0.310361  0.312605  0.314883  0.316188  ...  0.357042  0.358189  0.360090   \n",
       "14  0.552751  0.555931  0.558297  0.559510  ...  0.578482  0.585733  0.590542   \n",
       "15  0.523129  0.528769  0.532065  0.533796  ...  0.634057  0.641900  0.648078   \n",
       "16  0.533131  0.538122  0.540534  0.541680  ...  0.575887  0.582950  0.588388   \n",
       "17  0.526676  0.532259  0.535775  0.537460  ...  0.641014  0.647002  0.652938   \n",
       "18  0.568608  0.573251  0.575730  0.576395  ...  0.597621  0.602674  0.608327   \n",
       "19  0.527195  0.532015  0.534570  0.535710  ...  0.567889  0.572114  0.577310   \n",
       "20  0.548436  0.552928  0.555132  0.556085  ...  0.569908  0.574890  0.579650   \n",
       "21  0.518304  0.523846  0.527196  0.528963  ...  0.624452  0.630818  0.636017   \n",
       "22  0.521088  0.525895  0.528518  0.529579  ...  0.558759  0.563326  0.568172   \n",
       "23  0.557262  0.561686  0.563918  0.564966  ...  0.584689  0.589650  0.594564   \n",
       "24  0.522352  0.527095  0.529542  0.530865  ...  0.560366  0.565146  0.570067   \n",
       "25  0.530828  0.536697  0.540083  0.541840  ...  0.649341  0.655734  0.661060   \n",
       "26  0.528919  0.533447  0.536251  0.537478  ...  0.569300  0.574208  0.579266   \n",
       "27  0.542228  0.546772  0.549238  0.550202  ...  0.564819  0.569334  0.574500   \n",
       "28  0.546909  0.552853  0.556697  0.558499  ...  0.681535  0.688727  0.694635   \n",
       "29  0.528103  0.532526  0.535269  0.537373  ...  0.654794  0.663927  0.668777   \n",
       "30  0.539048  0.543052  0.545274  0.546327  ...  0.594621  0.602465  0.607290   \n",
       "31  0.573779  0.577161  0.579204  0.580219  ...  0.600184  0.608688  0.613170   \n",
       "32  0.554294  0.559353  0.562185  0.564044  ...  0.715527  0.725575  0.730782   \n",
       "33  0.543268  0.546478  0.548426  0.549551  ...  0.571308  0.578658  0.583329   \n",
       "34  0.557226  0.561918  0.565071  0.567110  ...  0.712978  0.722635  0.726949   \n",
       "35  0.571711  0.575421  0.577282  0.578127  ...  0.597686  0.605021  0.609750   \n",
       "36  0.532922  0.537205  0.539894  0.542135  ...  0.662726  0.668185  0.672794   \n",
       "37  0.539853  0.543294  0.545048  0.546487  ...  0.570347  0.574531  0.578717   \n",
       "38  0.562234  0.565789  0.567761  0.568793  ...  0.584056  0.588426  0.592124   \n",
       "39  0.529801  0.534197  0.537025  0.539145  ...  0.655903  0.661424  0.666222   \n",
       "\n",
       "         196       195       194       193       192       191       190  \n",
       "0   0.378832  0.378431  0.393099  0.397457  0.383589  0.416702  0.412296  \n",
       "1   0.372803  0.372285  0.386894  0.390989  0.377885  0.410304  0.406783  \n",
       "2   0.370988  0.370830  0.384763  0.388561  0.375848  0.407207  0.401769  \n",
       "3   0.365899  0.365903  0.379756  0.383695  0.371102  0.402973  0.397271  \n",
       "4   0.380391  0.380485  0.394986  0.399000  0.385428  0.418334  0.414698  \n",
       "5   0.370611  0.370509  0.384603  0.388456  0.375809  0.408066  0.403740  \n",
       "6   0.372112  0.371795  0.386025  0.389515  0.376903  0.408608  0.403582  \n",
       "7   0.365661  0.365655  0.379323  0.382975  0.370680  0.401890  0.396821  \n",
       "8   0.372427  0.372193  0.386862  0.390842  0.377482  0.409925  0.406347  \n",
       "9   0.381093  0.380869  0.395695  0.399594  0.385799  0.418890  0.415050  \n",
       "10  0.368811  0.368408  0.382670  0.386367  0.373508  0.405086  0.401146  \n",
       "11  0.365007  0.365193  0.379188  0.382527  0.370025  0.401027  0.395582  \n",
       "12  0.372921  0.372698  0.387175  0.391027  0.377442  0.409135  0.404400  \n",
       "13  0.370128  0.369602  0.383912  0.387541  0.374382  0.406033  0.401455  \n",
       "14  0.613888  0.613578  0.641193  0.658152  0.639821  0.697857  0.737987  \n",
       "15  0.674654  0.673527  0.704385  0.725900  0.705568  0.765985  0.817863  \n",
       "16  0.611248  0.610550  0.638514  0.656656  0.636711  0.694189  0.735069  \n",
       "17  0.679457  0.678738  0.709768  0.730871  0.710464  0.771010  0.823517  \n",
       "18  0.632288  0.631513  0.660739  0.679488  0.659816  0.718383  0.763266  \n",
       "19  0.599792  0.599206  0.626687  0.644546  0.625807  0.681970  0.719499  \n",
       "20  0.602128  0.601803  0.629407  0.646811  0.628488  0.685319  0.723862  \n",
       "21  0.661799  0.660737  0.691413  0.711125  0.691607  0.752104  0.800356  \n",
       "22  0.590187  0.589908  0.616733  0.633844  0.615769  0.671310  0.707839  \n",
       "23  0.617957  0.617361  0.645926  0.664113  0.645253  0.702766  0.743643  \n",
       "24  0.592316  0.591667  0.618951  0.635933  0.617671  0.673090  0.709623  \n",
       "25  0.688663  0.687729  0.718974  0.741030  0.721225  0.780686  0.835192  \n",
       "26  0.602097  0.601460  0.629124  0.646164  0.627012  0.683642  0.722129  \n",
       "27  0.596655  0.596382  0.623635  0.640834  0.621749  0.678265  0.715029  \n",
       "28  0.723585  0.722468  0.755459  0.779367  0.757648  0.818729  0.880280  \n",
       "29  0.694226  0.690244  0.718680  0.730858  0.708556  0.749574  0.789926  \n",
       "30  0.629643  0.627050  0.652382  0.662272  0.642538  0.682274  0.713994  \n",
       "31  0.636689  0.633971  0.661168  0.673055  0.652647  0.693504  0.729793  \n",
       "32  0.759440  0.754604  0.784805  0.799221  0.775027  0.816957  0.865353  \n",
       "33  0.604616  0.601764  0.626755  0.636840  0.616613  0.655967  0.684586  \n",
       "34  0.755167  0.750790  0.781049  0.795428  0.771656  0.813327  0.862812  \n",
       "35  0.633627  0.630575  0.657439  0.669161  0.649045  0.689069  0.725162  \n",
       "36  0.698132  0.693970  0.722730  0.734433  0.712463  0.752627  0.795034  \n",
       "37  0.599633  0.597276  0.621449  0.631180  0.612071  0.649248  0.678345  \n",
       "38  0.614623  0.611320  0.637047  0.647798  0.627007  0.666715  0.700410  \n",
       "39  0.690589  0.686825  0.714056  0.726491  0.704049  0.743363  0.784428  \n",
       "\n",
       "[40 rows x 2316 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5c502c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00672274, 0.01059934, 0.01616385],\n",
       "       [0.00704444, 0.0106038 , 0.01579774],\n",
       "       [0.00837255, 0.01219896, 0.01767969],\n",
       "       [0.00989189, 0.01339634, 0.01837363],\n",
       "       [0.01083554, 0.01524523, 0.02152408],\n",
       "       [0.00945782, 0.01350186, 0.01927102],\n",
       "       [0.01187528, 0.01688842, 0.0238318 ],\n",
       "       [0.01227732, 0.01672312, 0.02308867],\n",
       "       [0.01280096, 0.01830787, 0.0261066 ],\n",
       "       [0.01246109, 0.01842154, 0.0267948 ],\n",
       "       [0.01797896, 0.02487065, 0.03462324],\n",
       "       [0.01796561, 0.02471667, 0.03417083],\n",
       "       [0.01986065, 0.02826164, 0.04000596],\n",
       "       [0.02065663, 0.02869131, 0.04007639],\n",
       "       [0.0991701 , 0.10633115, 0.11677323],\n",
       "       [0.10962168, 0.11824789, 0.13018053],\n",
       "       [0.09972442, 0.10695899, 0.11689105],\n",
       "       [0.20958805, 0.25232609, 0.30625464],\n",
       "       [0.19461028, 0.23404347, 0.28398634],\n",
       "       [0.18872862, 0.22541464, 0.27199068],\n",
       "       [0.26271673, 0.31673904, 0.37654934],\n",
       "       [0.2882589 , 0.3476028 , 0.41247093],\n",
       "       [0.25863161, 0.31099003, 0.36934036],\n",
       "       [0.3798818 , 0.43823661, 0.48665518],\n",
       "       [0.36430862, 0.42045579, 0.46709381],\n",
       "       [0.42125273, 0.48553502, 0.53798744],\n",
       "       [0.43319565, 0.47730427, 0.50560593],\n",
       "       [0.42985977, 0.47348318, 0.50133075],\n",
       "       [0.51604282, 0.56692743, 0.59945619],\n",
       "       [0.08090369, 0.08966585, 0.10140163],\n",
       "       [0.07624968, 0.08355324, 0.09354939],\n",
       "       [0.07108665, 0.07838221, 0.08887965],\n",
       "       [0.09911323, 0.10882145, 0.12240159],\n",
       "       [0.07883375, 0.08562613, 0.09529182],\n",
       "       [0.09855781, 0.10881671, 0.12315614],\n",
       "       [0.0773019 , 0.08549567, 0.09683231],\n",
       "       [0.10432761, 0.12025925, 0.14214546],\n",
       "       [0.09063893, 0.10330794, 0.12086147],\n",
       "       [0.16561047, 0.20637662, 0.25804561],\n",
       "       [0.18952954, 0.23503651, 0.29230849]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = abs_data.iloc[:,2294:2297].values\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160d8012",
   "metadata": {},
   "source": [
    "## PCA and PLS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc83b524",
   "metadata": {},
   "source": [
    "#### Specify features (X) and target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "87d10e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = abs_data.iloc[:, 2294:2297].values\n",
    "y = abs_data[['Urea Concentration (mM)']].values.reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984b2d17",
   "metadata": {},
   "source": [
    "#### Fit principal component analysis (PCA) and partial least squares (PLS) regression models to the POUR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9029da5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCR r-squared 0.655\n",
      "PLS r-squared 0.655\n"
     ]
    }
   ],
   "source": [
    "pcr = make_pipeline(StandardScaler(), PCA(n_components=1), LinearRegression())\n",
    "pcr.fit(X_train, y_train)\n",
    "pca = pcr.named_steps[\"pca\"]  # retrieve the PCA step of the pipeline\n",
    "\n",
    "pls = PLSRegression(n_components=1)\n",
    "pls.fit(X_train, y_train)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "axes[0].scatter(pca.transform(X_test), y_test, alpha=0.3, label=\"ground truth\")\n",
    "axes[0].scatter(\n",
    "    pca.transform(X_test), pcr.predict(X_test), alpha=0.3, label=\"predictions\"\n",
    ")\n",
    "axes[0].set(\n",
    "    xlabel=\"Projected data onto first PCA component\", ylabel=\"y\", title=\"PCR / PCA\"\n",
    ")\n",
    "axes[0].legend()\n",
    "axes[1].scatter(pls.transform(X_test), y_test, alpha=0.3, label=\"ground truth\")\n",
    "axes[1].scatter(\n",
    "    pls.transform(X_test), pls.predict(X_test), alpha=0.3, label=\"predictions\"\n",
    ")\n",
    "axes[1].set(xlabel=\"Projected data onto first PLS component\", ylabel=\"y\", title=\"PLS\")\n",
    "axes[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"PCR r-squared {pcr.score(X_test, y_test):.3f}\")\n",
    "print(f\"PLS r-squared {pls.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecd0849",
   "metadata": {},
   "source": [
    "## Simple Dense NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc6f521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import tqdm\n",
    "from tqdm.keras import TqdmCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a5c22f",
   "metadata": {},
   "source": [
    "### Make dataset smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9a922537",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = abs_data.iloc[:, 2303:2307].values\n",
    "y = abs_data[['Urea Concentration (mM)']].values.reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9840564b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 49\n",
      "Trainable params: 49\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def simple_network():\n",
    "    # assemble the structure\n",
    "    model = Sequential()\n",
    "    # Note - THIS IS YOUR FIRST HIDDEN LAYER - input layer is defined by input_dim!\n",
    "    model.add(Dense(6, input_dim=6, kernel_initializer='normal', activation='relu'))\n",
    "    # This is the output layer\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    # compile the model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "my_model = simple_network()\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4a643f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a seed for random generation\n",
    "seed = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "664ab724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3c0231e974494fb3a7de71c04e7907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/j19a9k3/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /home/j19a9k3/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/j19a9k3/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/j19a9k3/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/j19a9k3/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/j19a9k3/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /home/j19a9k3/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /home/j19a9k3/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /home/j19a9k3/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_10 is incompatible with the layer: expected axis -1 of input shape to have value 6 but received input with shape [None, 4]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_262/675129890.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m estimator = KerasRegressor(build_fn=simple_network,\n\u001b[1;32m      5\u001b[0m         epochs=150, batch_size=10000, verbose=0)\n\u001b[0;32m----> 6\u001b[0;31m history = estimator.fit(X_train, y_train, validation_split=0.33, epochs=150, \n\u001b[0m\u001b[1;32m      7\u001b[0m         batch_size=10000, verbose=0, callbacks=TqdmCallback(verbose=0))\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 696\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    697\u001b[0m             *args, **kwds))\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3065\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/j19a9k3/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /home/j19a9k3/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/j19a9k3/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/j19a9k3/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/j19a9k3/miniconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/j19a9k3/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /home/j19a9k3/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /home/j19a9k3/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /home/j19a9k3/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:212 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_10 is incompatible with the layer: expected axis -1 of input shape to have value 6 but received input with shape [None, 4]\n"
     ]
    }
   ],
   "source": [
    "# initialize the random number generator - i.e. get reproducible starting weights\n",
    "np.random.seed(seed)\n",
    "# create the NN framework\n",
    "estimator = KerasRegressor(build_fn=simple_network,\n",
    "        epochs=150, batch_size=10000, verbose=0)\n",
    "history = estimator.fit(X_train, y_train, validation_split=0.33, epochs=150, \n",
    "        batch_size=10000, verbose=0, callbacks=TqdmCallback(verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ff9e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
